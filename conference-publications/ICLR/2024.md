# [Publications in ICLR 2024](https://openreview.net/group?id=ICLR.cc/2024/Conference#tab-accept-oral)

## Accept domain statistics
 - **Time Series Forecasting: 15**
 - **Time Series Representation Learning: 8**
 - **Time Series Generative Learning: 6**
 - **Time Series Analysis: 8**
 - **Miscellaneous: 2**
## Time Series Forecasting
### TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=YH5w12OUuU&name=pdf)]
 - 过去十年见证了深度学习时间序列建模的重大进步。 虽然实现了最先进的结果，但性能最佳的架构在不同的应用程序和领域之间存在很大差异。 另一方面，对于自然语言处理，生成式预训练 Transformer (GPT) 通过跨各种文本数据集训练一个通用模型，展示了令人印象深刻的性能。 探索 GPT 类型的架构是否能够有效地处理时间序列、捕获内在的动态属性并导致准确性的显着提高是很有趣的。 在本文中，我们提出了一种新颖的框架 TEMPO，它可以有效地学习时间序列表示。 我们专注于利用预训练模型的时间序列任务的两个基本归纳偏差：（i）趋势、季节性和残差成分之间复杂相互作用的分解； (ii) 引入基于选择的提示，以促进非平稳时间序列中的分布适应。 TEMPO 扩展了根据不同领域内的数据对现实世界时间现象进行动态建模的能力。 我们的实验证明了 TEMPO 的卓越性能，在许多时间序列基准数据集上比最先进的方法提高了 20%-60%。 这种性能增益不仅在标准监督学习设置中观察到，而且在涉及以前未见过的数据集的场景中也观察到。 这一引人注目的发现凸显了 TEMPO 构成基础模型构建框架的潜力。
   
### TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series
 - [[paper](https://openreview.net/attachment?id=xtOydkE1Ku&name=pdf)]
 - 我们引入了一种新的多元概率时间序列预测模型，旨在灵活地解决一系列任务，包括预测、插值及其组合。 基于 copula 理论，我们为最近引入的基于变压器的注意力 copula（TACTiS）提出了一个简化的目标，其中分布参数的数量现在与变量的数量成线性而不是阶乘。 新的目标需要引入培训课程，这与对原始架构的必要改变密切相关。 我们表明，所得模型具有明显更好的训练动态，并在不同的现实世界预测任务中实现了最先进的性能，同时保持了先前工作的灵活性，例如无缝处理未对齐和不均匀采样的时间序列。
   
### Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=lJkOCMP2aW&name=pdf)]
 - 基于 Transformer 的模型在时间序列预测方面取得了一些成功。 现有方法主要从有限或固定的尺度对时间序列进行建模，这使得捕获跨不同尺度的不同特征具有挑战性。 在本文中，我们提出了具有自适应路径的多尺度变压器（Pathformer）。 所提出的 Transformer 集成了时间分辨率和时间距离以进行多尺度建模。 多尺度划分使用不同大小的块将时间序列划分为不同的时间分辨率。 基于每个尺度的划分，对这些补丁执行双重关注，以捕获全局相关性和局部细节作为时间依赖性。 我们进一步丰富了具有自适应路径的多尺度变压器，它根据输入时间序列中变化的时间动态自适应地调整多尺度建模过程，提高了 Pathformer 的预测精度和泛化能力。 对九个真实世界数据集的大量实验表明，Pathformer 不仅超越了当前所有模型，实现了最先进的性能，而且在各种传输场景下表现出了更强的泛化能力。
   
### VQ-TR: Vector Quantized Attention for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=IxpTsFS7mh&name=pdf)]
 - 概率时间序列预测是一个具有挑战性的问题，因为涉及的序列较长，准确的概率推理需要大量样本，并且许多应用程序需要实时推理。 这些挑战需要不仅准确而且计算高效的方法。 不幸的是，当前最先进的时间序列预测方法都是基于 Transformer，由于序列长度的二次复杂性，其扩展性很差，因此计算效率低下。 此外，除了少数例外，这些方法仅针对非概率点估计进行了评估。 在这项工作中，我们解决了这两个缺点。 首先，我们引入 VQ-TR，它将大序列映射到一组离散的潜在表示，作为注意力模块的一部分。 这不仅使我们能够关注序列长度具有线性复杂性的较大上下文窗口，而且还允许有效的正则化以避免过度拟合。 对于第二个问题，我们提供了据我们所知对现代基于 Transformer 的概率预测时间序列预测方法的首次系统比较。 在此比较中，我们发现 VQ-TR 的性能比所有其他方法更好或相当，同时计算效率较高。
   
### Multi-Resolution Diffusion Models for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=mmjnr0G8ZY&name=pdf)]
 - 扩散模型已成功用于许多计算机视觉应用，例如文本引导的图像生成和图像到图像的翻译。 最近，有人尝试扩展时间序列数据的扩散模型。 然而，这些扩展相当简单，并且没有利用时间序列数据的独特属性。 由于不同的模式通常在时间序列的多个尺度上表现出来，因此我们在本文中利用这种多分辨率时间结构并提出了多分辨率扩散模型（mr-Diff）。 通过使用季节趋势分解，我们从时间序列中依次提取从细到粗的趋势以进行前向扩散。 然后，去噪过程以一种由易到难的非自回归方式进行。 首先生成最粗略的趋势。 使用预测的粗略趋势作为条件变量，逐步添加更精细的细节。 九个真实世界时间序列数据集的实验结果表明，mr-Diff 优于最先进的时间序列扩散模型。 它也优于或可比各种高级时间序列预测模型。

### CARD: Channel Aligned Robust Blend Transformer for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=MJksrOhurE&name=pdf)]
 - [[code](https://anonymous.4open.science/r/CARD-6EEC)]
 - 最近的研究证明了 Transformer 模型在时间序列预测方面的强大功能。 Transformer 成功的关键要素之一是提高训练鲁棒性的通道无关（CI）策略。 然而，忽略 CI 中不同通道之间的相关性会限制模型的预测能力。 在这项工作中，我们设计了一种特殊的 Transformer，即通道对齐鲁棒混合变压器（Channel Aligned Robust Blend Transformer，简称 CARD），它解决了 CI 型 Transformer 在时间序列预测中的关键缺点。 首先，CARD 引入了通道对齐的注意力结构，使其能够捕获信号之间的时间相关性以及多个变量之间随时间的动态依赖性。 其次，为了有效利用多尺度知识，我们设计了一个令牌混合模块来生成具有不同分辨率的令牌。 第三，我们引入了用于时间序列预测的稳健损失函数，以减轻潜在的过度拟合问题。 这种新的损失函数根据预测不确定性对有限范围内的预测重要性进行加权。 我们对多个长期和短期预测数据集的评估表明，CARD 显着优于最先进的时间序列预测方法。
   
### Transformer-Modulated Diffusion Models for Probabilistic Multivariate Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=qae04YACHs&name=pdf)]
 - Transformer 在多元时间序列 (MTS) 预测中得到了广泛应用，提供了令人印象深刻的性能。 尽管如此，这些现有的基于变压器的方法往往忽略了一个重要方面：将不确定性纳入预测序列，这在决策中具有重要价值。 在本文中，我们引入了变压器调制扩散模型（TMDM），将条件扩散生成过程与变压器结合到一个统一的框架中，以实现 MTS 的精确分布预测。 TMDM 利用变压器的力量从历史时间序列数据中提取重要的见解。 然后，该信息被用作先验知识，捕获扩散模型内正向和反向过程中的协变量依赖性。 此外，我们将精心设计的基于变压器的预测方法无缝集成到 TMDM 中，以提高其整体性能。 此外，我们引入了两个新的指标来评估不确定性估计性能。 通过使用四个评估指标对六个数据集进行广泛的实验，我们确定了 TMDM 在概率 MTS 预测中的有效性。

### Interpretable Sparse System Identification: Beyond Recent Deep Learning Techniques on Time-Series Prediction
 - [[paper](https://openreview.net/attachment?id=aFWUY3E7ws&name=pdf)]
 - 随着神经网络方法的不断进步，时间序列预测在过去几十年中引起了人们的极大兴趣。 然而，神经网络的可解释性不足，并且利用深度学习技术进行预测需要大量的计算支出，导致其在许多场景中的应用变得困难。 为了应对这一挑战，本研究提出了一种可解释的稀疏系统识别方法，该方法不需要通过反向传播进行耗时的训练。 该方法融合了基于知识和数据驱动方法的优点，利用傅里叶基础并考虑数据背后的长期趋势和短期波动来构建字典函数。 利用l1范数进行稀疏优化，可以获得具有显式稀疏表达函数和极高准确度的预测结果。 该方法的性能评估是在综合基准数据集上进行的，包括 ETT、Exchange 和 ILI。 结果表明，根据最新最先进的深度学习方法，我们提出的方法总体显着提高了 20% 以上。 此外，我们的方法展示了仅在 CPU 上的高效训练能力。 因此，这项研究可能会对时间序列重建和预测领域有所启发。

### Copula Conformal prediction for multi-step time series prediction
 - [[paper](https://openreview.net/attachment?id=ojIJZDNIBj&name=pdf)]
 - 准确的不确定性测量是构建稳健可靠的机器学习系统的关键步骤。 共形预测是一种无分布的不确定性量化算法，因其易于实现、统计覆盖范围保证以及底层预测器的多功能性而广受欢迎。 然而，现有的时间序列共形预测算法仅限于单步预测，没有考虑时间依赖性。 在本文中，我们提出了用于多元、多步时间序列预测的 Copula 保形预测算法，CopulaCPTS。 我们证明了CopulaCPTS具有有限样本有效性保证。 在四个合成和现实世界的多元时间序列数据集上，我们表明 CopulaCPTS 比现有技术为多步骤预测任务生成更校准和更有效的置信区间。
   
### Towards Transparent Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=TYXtXLYHpR&name=pdf)]
 - 透明的机器学习 (ML) 模型对于确保决策系统的可解释性和可信性至关重要，特别是在医疗保健、金融和刑事司法等高风险领域。 虽然透明的机器学习模型已被提出用于分类和回归，但时间序列预测为确保透明度带来了一些独特的挑战。 特别是，当前使用的自下而上的方法侧重于特定时间点（通常间隔时间）的时间序列值，并不能提供对整个时间序列的整体理解。 这限制了机器学习在许多关键领域的适用性。 为了为机器学习打开这些领域，我们提出了一个自上而下的双层透明度框架，其中涉及了解预测时间序列的较高级别趋势和较低级别属性。 应用该框架，我们开发了 TIMEVIEW，这是一种基于静态特征的透明机器学习模型，用于时间序列预测，并辅以交互式可视化工具。 通过一系列实验，我们展示了我们方法的有效性和可解释性，为机器学习在各个领域更透明和可靠的应用铺平了道路。
   
### iTransformer: Inverted Transformers Are Effective for Time Series Forecasting 
 - [[paper](https://openreview.net/attachment?id=JePfAI8fah&name=pdf)]
 - 最近线性预测模型的繁荣对基于 Transformer 的预测器的架构修改的持续热情提出了质疑。 这些预测器利用 Transformer 对时间序列的时间标记 *temporal tokens* 的全局依赖关系进行建模，每个标记由同一时间戳的多个变量形成。 然而，由于性能下降和计算爆炸，Transformers 在预测具有较大**回溯窗口**的序列时面临挑战。 此外，每个时间标记的统一嵌入*embedding*融合了具有潜在未对齐时间戳和不同物理测量的多个变量，这可能无法学习以变量为中心的表示并导致无意义的注意力图。 在这项工作中，我们反思了 Transformer 组件的职责，并在不对基本组件进行任何修改的情况下重新调整了 Transformer 架构的用途。 我们提出 **iTransformer**，它简单地将注意力和前馈网络应用于反转维度。 具体来说，各个系列的时间点被嵌入到变量标记中，注意力机制利用变量标记来捕获多元相关性； 同时，前馈网络应用于每个变量标记来学习非线性表示。 iTransformer 模型在具有挑战性的现实世界数据集上达到了最先进的水平，这进一步增强了 Transformer 系列的性能、跨不同变量的泛化能力，以及更好地利用任意回溯窗口，使其成为一个很好的替代方案 时间序列预测的基本支柱。

### TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting
 - [[paper](https://openreview.net/attachment?id=7oLshfEIC2&name=pdf)]
 - 时间序列预测广泛应用于交通规划和天气预报等广泛应用中。 然而，现实世界的时间序列通常呈现复杂的时间变化，使得预测极具挑战性。 超越简单分解和多周期分析的主流范式，我们以多尺度混合的新颖观点分析时间变化，该观点基于直观但重要的观察，即时间序列在不同采样尺度下呈现不同的模式。 微观和宏观信息分别反映在精细和粗尺度上，从而可以从本质上理清复杂的变化。 基于这一观察，我们提出 **TimeMixer** 作为完全基于 MLP 的架构，具有过去可分解混合 (PDM) 和未来多重预测混合 (FMM) 模块，以在过去的提取和未来的预测阶段充分利用解开的多尺度序列。 具体来说，PDM将分解应用于多尺度序列，进一步将分解后的季节成分和趋势成分分别在由细到粗和由粗到细的方向上混合，依次聚合微观季节和宏观趋势信息。 FMM 进一步集成了多个预测变量，以在多尺度观测中利用互补的预测功能。 因此，TimeMixer 能够在长期和短期预测任务中实现一致的最先进性能，并具有良好的运行时效率。

### Biased Temporal Convolution Graph Network for Time Series Forecasting with Missing Values.
 - [[paper](https://openreview.net/attachment?id=O9nZCwdGcG&name=pdf)]
 - [[code](https://anonymous.4open.science/r/BiaTCGNet-1F80/README.md)]
 - 多元时间序列预测在气象研究、交通管理和经济规划等各种应用中发挥着重要作用。 在过去的几十年中，通过探索时间动态和空间相关性，人们为实现准确可靠的预测做出了许多努力。 特别是，近年来基于 Transformer 的方法的发展显着提高了长期预测的准确性。 现有的预测方法通常假设输入数据完整，然而，在实践中，由于设备故障或昂贵的数据采集，时间序列数据经常被部分观察到，这可能严重阻碍现有方法的性能。 简单地使用插补方法不可避免地会涉及误差积累并导致次优解决方案。 受此启发，我们提出了一种偏置时间卷积图网络，它共同捕获时间依赖性和空间结构。 特别是，我们将偏差注入到两个精心开发的模块中——多尺度实例 PartialTCN 和偏差 GCN——以解释缺失的模式。 实验结果表明，我们提出的模型能够在五个真实世界基准数据集上比现有方法实现高达 9.93% 的改进。

### RobustTSF: Towards Theory and Design of Robust Time Series Forecasting with Anomalies
 - [[paper](https://openreview.net/attachment?id=ltZ9ianMth&name=pdf)]
 - 时间序列预测是许多现实应用中的一项重要且前沿的任务。 然而，大多数时间序列预测技术都假设训练数据是干净的，没有异常。 这种假设是不现实的，因为收集的时间序列数据在实践中可能会受到污染。 如果直接用有异常的时间序列来训练，预测模型的效果会较差。 因此，有必要开发从污染数据中自动学习稳健预测模型的方法。 在本文中，我们首先统计定义了三类异常，然后从理论上和实验上分析了这些异常存在时的损失鲁棒性和样本鲁棒性。 根据我们的分析，我们提出了一种简单而有效的算法来学习稳健的预测模型。 大量的实验表明，我们的方法非常稳健，并且优于所有现有方法。

### STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction
 - [[paper](https://openreview.net/attachment?id=6iwg437CZs&name=pdf)]
 - 我们提出了 **STanHop-Net**（稀疏串联 Hopfield 网络），用于具有内存增强功能的多元时间序列预测。 我们方法的核心是 STanHop，一种新颖的基于 Hopfield 的神经网络块，它以数据依赖的方式稀疏地学习和存储时间和跨序列表示。 本质上，STanHop 使用两个串联稀疏 Hopfield 层顺序学习时间表示和跨系列表示。 此外，StanHop 还包含两个额外的外部内存模块：即插即用模块和调谐即用模块，分别用于无训练和任务感知内存增强。 它们使 StanHop-Net 能够快速响应某些突发事件。 在方法上，我们通过以分层方式堆叠 STanHop 块来构建 StanHop-Net，从而实现具有特定于分辨率的稀疏性的多分辨率特征提取。 理论上，我们引入了现代 Hopfield 模型的稀疏扩展（广义稀疏现代 Hopfield 模型），并表明与密集模型相比，它在不牺牲记忆容量的情况下赋予了更严格的记忆检索错误。 根据经验，我们验证了我们的框架在合成和现实环境中的有效性。

## Time Series Representation Learning
### Soft Contrastive Learning for Time Series
- [[paper](https://openreview.net/attachment?id=pAsQSWlDUf&name=pdf)]
- 对比学习已被证明可以有效地以自我监督的方式学习时间序列的表示。 然而，对比时间序列中相邻时间戳的相似时间序列实例或值会导致忽略它们固有的相关性，从而导致学习表示的质量恶化。 为了解决这个问题，我们提出了 **SoftCLT**，一种简单而有效的时间序列软对比学习策略。 这是通过引入实例和时间对比损失以及范围从 0 到 1 的软分配来实现的。 具体来说，我们定义了软分配：1）按数据空间上时间序列之间的距离计算的实例对比损失，以及2）按时间戳差异计算的时间对比损失。 SoftCLT 是一种用于时间序列对比学习的即插即用方法，可以提高学习表示的质量，而无需附加任何附加功能。 在实验中，我们证明 SoftCLT 持续提高了各种下游任务的性能，包括分类、半监督学习、迁移学习和异常检测，显示出最先进的性能。
  
### Towards Enhancing Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach
 - [[paper](https://openreview.net/attachment?id=K2c04ulKXn&name=pdf)]
 - [[code](https://anonymous.4open.science/r/DynamicBadPairMining_ICLR24-2562/README.md)]
 - 并非所有正对都有益于时间序列对比学习。 在本文中，我们研究了两种类型的不良正对，它们会损害通过对比学习学习到的时间序列表示的质量：噪声正对和错误正对。 我们观察到，由于存在噪声正对，模型倾向于简单地学习噪声模式（噪声对齐）。 同时，当出现错误的正对时，模型会浪费大量精力来对齐非代表性模式（错误对齐）。 为了解决这个问题，我们提出了一种动态坏对挖掘（DBPM）算法，该算法可以可靠地识别和抑制时间序列对比学习中的坏正对。 具体来说，DBPM 利用内存模块来动态跟踪训练过程中每个正对的训练行为。 这使我们能够根据历史训练行为识别每个时期的潜在不良正对。 随后通过转换模块降低识别出的不良对的权重，从而减轻它们对表示学习过程的负面影响。 DBPM 是一种简单的算法，设计为轻量级插件，无需学习参数，可增强现有最先进方法的性能。 通过在四个大型真实时间序列数据集上进行的广泛实验，我们证明了 DBPM 在减轻不良正对的不利影响方面的功效。
   
### Retrieval-Based Reconstruction For Time-series Contrastive Learning
 - [[paper](https://openreview.net/attachment?id=3zQo5oUvia&name=pdf)]
 - 自监督对比学习的成功取决于识别正数据对，当将这些数据对推到嵌入空间中时，为后续下游任务编码有用信息。 然而，在时间序列中，这是具有挑战性的，因为通过增强创建正对可能会破坏原始语义。 我们假设，如果我们可以从一个子序列中检索信息以成功重建另一个子序列，那么它们应该形成一对正对。 利用这种直觉，我们介绍了我们的新颖方法：基于检索的重建（REBAR）对比学习。 首先，我们利用卷积交叉注意力架构来计算两个不同时间序列之间的 REBAR 误差。 然后，通过验证实验，我们表明 REBAR 误差是相互类成员关系的预测因子，证明其作为正/负标记器的使用是合理的。 最后，一旦集成到对比学习框架中，我们的 REBAR 方法就可以学习一种嵌入，从而在各种模式的下游任务上实现最先进的性能。
   
### Disentangling Time Series Representations via Contrastive based $l$-Variational Inference
 - [paper](https://openreview.net/attachment?id=iI7hZSczxE&name=pdf)
 - [[code](https://anonymous.4open.science/r/DIoSC)]
 - 学习解缠结的表示对于时间序列至关重要，它提供了特征推导和改进的可解释性等好处，从而提高了任务性能。 我们专注于家用电器用电的解开表示学习，使用户能够了解和优化他们的消费，以减少碳足迹。 我们的方法将问题描述为理清每个属性在总消费中的作用（例如洗碗机、冰箱等）。 与假设属性独立的现有方法不同，我们承认现实世界的时间序列属性相关性，例如冬季洗碗机和洗衣机的运行。 为了解决这个问题，我们采用弱监督对比解开，促进不同相关场景和新家庭之间的表征泛化。 我们的方法利用具有自注意力的创新 l-变分推理层，有效解决自下而上和自上而下网络之间的时间依赖性。 我们发现 DIoSC（通过对比学习解开和独立支持）可以增强重建个体电器用电量的任务。 我们引入 TDS（时间解缠结分数）来衡量解缠质量。 TDS 可靠地反映了解缠结性能，使其成为评估时间序列表示的有价值的指标。

### Parametric Augmentation for Time Series Contrastive Learning
 - [[paper](https://openreview.net/attachment?id=EIPLdFy3vp&name=pdf)]
 - 对比学习等现代技术已被有效地应用于许多领域，包括计算机视觉、自然语言处理和图结构数据。 创建积极的例子来帮助模型学习稳健和有区别的表示是对比学习方法的关键阶段。 通常，预设的人类直觉指导相关数据增强的选择。 由于人类容易识别的模式，这种经验法则在视觉和语言领域很有效。 然而，直观地检查时间序列中的时间结构是不切实际的。 数据集和实例级别的时间序列增强的多样性使得很难动态选择有意义的增强。 在本研究中，我们通过使用信息论分析时间序列数据增强并以统一格式总结最常用的增强来解决这一差距。 然后，我们提出了一种具有参数增强的对比学习框架 **AutoTCL**，它可以自适应地用于支持时间序列表示学习。 所提出的方法与编码器无关，使其能够与不同的骨干编码器无缝集成。 单变量预测任务的实验证明了我们的方法具有高度竞争力的结果，与领先基线相比，MSE 平均降低了 6.5%，MAE 平均降低了 4.7%。 在分类任务中，AutoTCL 的平均准确率提高了 1.2%。

### Explaining Time Series via Contrastive and Locally Sparse Perturbations
 - [[paper](https://openreview.net/attachment?id=qDdSRaOiyb&name=pdf)]
 - [[code](https://anonymous.4open.science/r/ContraLSP-1146/)]
 - 解释多元时间序列是一项复合挑战，因为它需要识别时间序列中的重要位置并匹配复杂的时间模式。 尽管以前的基于显着性的方法解决了这些挑战，但它们的扰动可能无法缓解分布偏移问题，这在异质样本中是不可避免的。 我们提出了 ContraLSP，一种局部稀疏模型，它引入反事实样本来构建无信息的扰动，但使用对比学习来保持分布。 此外，我们结合了特定于样本的稀疏门来生成更多二元倾斜和平滑的掩模，这可以轻松地整合时间趋势并简约地选择显着特征。 对合成数据集和真实数据集的实证研究表明，ContraLSP 的性能优于最先进的模型，证明时间序列数据的解释质量有了显着提高。
   
### Learning to Embed Time Series Patches Independently
 - [[paper](https://openreview.net/attachment?id=WS7GuBDFa2&name=pdf)]
 - 掩蔽时间序列建模最近作为时间序列的自监督表示学习策略而受到广泛关注。 受到计算机视觉中屏蔽图像建模的启发，最近的工作首先对时间序列进行修补和部分屏蔽，然后训练 Transformer 通过从未屏蔽的补丁中预测屏蔽的补丁来捕获补丁之间的依赖关系。 然而，我们认为捕获此类补丁依赖关系可能不是时间序列表示学习的最佳策略； 相反，学习独立嵌入补丁会产生更好的时间序列表示。 具体来说，我们建议使用 1) 简单的补丁重建任务，它自动编码每个补丁而不查看其他补丁，以及 2) 独立嵌入每个补丁的简单的逐补丁 MLP。 此外，我们引入互补对比学习来有效地分层捕获相邻时间序列信息。 与最先进的基于 Transformer 的模型相比，我们提出的方法提高了时间序列预测和分类性能，同时在参数数量和训练时间方面更加高效。
      
### T-Rep: Representation Learning for Time Series using Time-Embeddings
 - [[paper](https://openreview.net/attachment?id=3y2TfP966N&name=pdf)]
 - 多元时间序列对标准机器学习技术提出了挑战，因为它们通常是无标签的、高维的、有噪声的并且包含丢失的数据。 为了解决这个问题，我们提出了 **T-Rep**，一种以时间步粒度学习时间序列表示的自监督方法。 T-Rep 与其特征提取器一起学习时间的向量嵌入，以从信号中提取时间特征，例如趋势、周期性或分布偏移。 这些时间嵌入在借口任务中得到利用，以将平滑且细粒度的时间依赖性纳入表示中，并增强对丢失数据的鲁棒性。 我们在下游分类、预测和异常检测任务上评估 T-Rep。 与现有的时间序列自监督算法相比，它在所有三个任务中都表现出色。 我们在缺失数据的情况下测试了 T-Rep，事实证明它比同类产品更具弹性。 最后，我们提供了潜在空间可视化实验，强调了所学习的表示的可解释性。

## Time Series Generative Learning
### TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series
 - [[paper](https://openreview.net/attachment?id=Tuh4nZVb0g&name=pdf)]
 - 这项工作总结了在当今的大型语言模型 (LLM) 环境中完成时间序列 (TS) 任务的两种方法：LLM-for-TS（以模型为中心）设计和训练基本的大型模型，或微调预训练的模型 TS数据法学硕士； TS-for-LLM（以数据为中心）将 TS 转换为模型友好的表示形式，使预训练的 LLM 能够处理 TS 数据。 鉴于数据缺乏、资源有限、语义上下文要求等问题，本工作重点关注TSfor-LLM，旨在通过设计适合LLM的TS嵌入方法来激活LLM对TS数据的能力。 所提出的方法被命名为TEST。 它首先对 TS 进行标记，构建一个编码器通过实例方式、特征方式和文本原型对齐对比来嵌入 TS，其中 TS 嵌入空间与 LLM 的嵌入层空间对齐，然后创建软提示以使 LLM 更加开放 到该嵌入，最后使用冻结的 LLM 实现 TS 任务。 我们还通过理论和实验证明了TS-for-LLM的可行性。 使用八个不同结构和规模的冻结 LLM 进行 TS 分类、预测和表示任务的实验。 结果表明，采用 TEST 策略的预训练 LLM 可以实现比当今的 SOTA TS 模型更好或相当的性能，并为少样本和泛化带来好处。 通过将LLM视为模式机，TEST可以在不影响语言能力的情况下赋予LLM处理TS数据的能力。 我们希望这项研究能够成为未来支持 TS+LLM 进展的工作基础。
   
### MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process
 - [[paper](https://openreview.net/attachment?id=CZiY6OLktd&name=pdf)]
 - 最近，扩散概率模型由于其生成高保真样本的卓越能力而在生成时间序列预测中引起了人们的关注。 然而，在概率时间序列预测任务中有效利用它们强大的建模能力仍然是一个悬而未决的问题，部分原因是它们的随机性带来的不稳定性的挑战。 为了应对这一挑战，我们引入了一种新颖的多粒度时间序列扩散 **（MG-TSD）** 模型，该模型通过利用数据中固有的粒度级别作为中间扩散步骤的给定目标来实现最先进的预测性能 指导扩散模型的学习过程。 构建目标的方法是通过观察扩散模型的前向过程（依次将数据分布破坏为标准正态分布）而激发的，该过程直观地与将细粒度数据平滑为粗粒度表示的过程一致， 这两者都会导致精细分布特征逐渐丧失。 在研究中，我们推导了一种新颖的多粒度引导扩散损失函数，并提出了一种简洁的实现方法，以有效利用各种粒度级别的粗粒度数据。 更重要的是，我们的方法不依赖额外的外部数据，使其具有通用性并适用于各个领域。 对现实世界数据集进行的大量实验表明，我们的 MG-TSD 模型优于现有的时间序列预测方法。
   
### Diffusion-TS: Interpretable Diffusion for General Time Series Generation
 - [[paper](https://openreview.net/attachment?id=4h1apFjO99&name=pdf)]
 - 去噪扩散概率模型（DDPM）正在成为生成模型的领先范例。 它最近在音频合成、时间序列插补和预测方面取得了突破。 在本文中，我们提出了 **Diffusion-TS**，一种基于扩散的新型框架，它通过使用具有解纠缠时间表示的编码器-解码器 Transformer 生成高质量的多元时间序列样本，其中分解技术指导 Diffusion-TS 捕获语义 时间序列的含义，而 Transformer 从噪声模型输入中挖掘详细的序列信息。 与现有方法不同，我们训练模型直接重建样本，而不是每个扩散步骤中的噪声，并结合基于傅立叶的损失项。 此外，结果表明，所提出的 Diffusion-TS 可以轻松扩展到条件生成任务，例如预测和插补，而无需任何模型更改。 这也激励我们进一步探索DiffusionTS在不规则设置下的表现。 最后，通过定性和定量实验，结果表明 Diffusion-TS 在时间序列的各种现实分析上取得了最先进的结果。
   
### Time-LLM: Time Series Forecasting by Reprogramming Large Language Models
 - [[paper](https://openreview.net/attachment?id=Unb5CVPtae&name=pdf)]
 - 时间序列预测在许多现实世界的动态系统中具有重要意义，并且已被广泛研究。 与自然语言处理 (NLP) 和计算机视觉 (CV) 中单个大型模型可以处理多个任务不同，时间序列预测模型通常是专门化的，需要针对不同的任务和应用程序进行不同的设计。 虽然预训练的基础模型在 NLP 和 CV 领域取得了令人印象深刻的进步，但它们在时间序列领域的发展却受到数据稀疏性的限制。 最近的研究表明，大型语言模型（LLM）对复杂的标记序列具有强大的模式识别和推理能力。 然而，如何有效地对齐时间序列数据和自然语言的模态以利用这些功能仍然是一个挑战。 在这项工作中，我们提出了 **TIME-LLM**，这是一个重新编程框架，可将 LLM 重新用于一般时间序列预测，同时保持主干语言模型不变。 我们首先使用文本原型对输入时间序列进行重新编程，然后将其输入到冻结的法学硕士中以对齐两种模式。 为了增强法学硕士利用时间序列数据进行推理的能力，我们提出了提示作为前缀（PaP），它丰富了输入上下文并指导重新编程的输入补丁的转换。 最后对 LLM 转换后的时间序列补丁进行投影以获得预测。 我们的综合评估表明，TIME-LLM 是一个强大的时间序列学习器，其性能优于最先进的专业预测模型。 此外，TIME-LLM 在少样本和零样本学习场景中都表现出色。
   
### Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs
 - [[paper](https://openreview.net/attachment?id=eY7sLb0dVF&name=pdf)]
 - [[code](https://anonymous.4open.science/r/Time-LLM)]
 - 生成真实的时间序列数据对于许多工程和科学应用都很重要。 现有的工作使用生成对抗网络（GAN）来解决这个问题。 然而，GAN 在训练过程中通常不稳定，并且可能会出现模式崩溃。 虽然众所周知，变分自动编码器（VAE）对于这些问题更加稳健，但（令人惊讶的是）它们很少被考虑用于时间序列生成。 在这项工作中，我们引入了 **Koopman VAE (KVAE)**，这是一种新的生成框架，它基于模型先验的新颖设计，并且可以针对规则和不规则训练数据进行优化。 受库普曼理论的启发，我们使用线性映射来表示潜在的条件先验动力学。 我们的方法通过两个所需的功能增强了生成建模：（i）可以通过利用对线性映射的特征值规定约束的光谱工具来实现合并领域知识； (ii) 可以使用动力系统理论的工具来研究系统的定性行为和稳定性。 我们的结果表明，在几个具有挑战性的合成和现实时间序列生成基准中，KVAE 的性能优于最先进的 GAN 和 VAE 方法。 无论是使用常规数据还是不规则数据进行训练，KVAE 都会生成可提高判别性和预测性指标的时间序列。 我们还提供了视觉证据，表明 KVAE 学习的概率密度函数可以更好地逼近经验地面真实分布
   
### Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns
 - [[paper](https://openreview.net/attachment?id=CdjnzWsQax&name=pdf)]
 - 有限的数据可用性构成了训练金融应用深度学习模型的主要障碍。 由于与金融时间序列相关的不规则且尺度不变的模式（以不同的持续时间和幅度重复的时间动态），合成金融时间序列以增强现实世界的数据具有挑战性。 现有方法无法捕获这种动态，现有方法通常假设基础数据具有规律性和一致性。 我们开发了一种名为 **FTS-Diffusion** 的新颖生成框架，用于对由三个模块组成的不规则和尺度不变模式进行建模。 首先，我们开发了一种尺度不变的模式识别算法来提取持续时间和幅度变化的重复模式。 其次，我们构建一个基于扩散的生成网络来合成模式片段。 第三，我们对模式的时间转换进行建模，以聚合生成的片段。 大量实验表明，FTS-Diffusion 生成的合成金融时间序列与观察到的数据高度相似，优于最先进的替代方案。 两个下游实验表明，使用 FTS-Diffusion 生成的合成数据增强现实世界数据可将股市预测的误差降低高达 17.9%。 据我们所知，这是第一个生成具有不规则和尺度不变模式的复杂时间序列的工作，解决金融中的数据限制问题。

## Time Series Analysis
### Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators
 - [[paper](https://openreview.net/attachment?id=JiTVtCUOpS&name=pdf)]
 - 最近，与通道无关的方法在多元时间序列（MTS）预测中取得了最先进的性能。 尽管降低了过度拟合的风险，但这些方法错过了利用通道依赖性进行准确预测的潜在机会。 我们认为变量之间存在局部固定的超前滞后关系，即一些滞后变量可能在短时间内跟随领先指标。 利用这种渠道依赖性是有益的，因为领先指标提供了可用于降低滞后变量的预测难度的预先信息。 在本文中，我们提出了一种名为 LIFT 的新方法，该方法首先有效地估计领先指标及其在每个时间步的领先步骤，然后明智地允许滞后变量利用领先指标的先进信息。 LIFT 作为一个插件，可以与任意时间序列预测方法无缝协作。 对六个真实世界数据集的大量实验表明，LIFT 将最先进方法的平均预测性能提高了 5.9%。
   
### CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery
 - [[paper](https://openreview.net/attachment?id=iad1yyyGme&name=pdf)]
 - [[code](www.causaltime.cc)]
 - 时间序列因果发现（TSCD）是机器学习的一个基本问题。 然而，现有的合成数据集无法正确评估或预测算法在真实数据上的性能。 本研究引入了 **CausalTime** 管道来生成与真实数据高度相似的时间序列，并使用真实因果图进行定量性能评估。 该管道从特定场景中的真实观察开始，并生成匹配的基准数据集。 首先，我们利用深度神经网络和标准化流程来准确捕捉现实动态。 其次，我们通过对神经网络进行重要性分析或利用先验知识来提取假设的因果图。 第三，我们通过将因果模型分为因果项、残差项和噪声项来导出真实因果图。 最后，使用拟合网络和导出的因果图，我们生成适合算法评估的相应通用时间序列。 在实验中，我们通过定性和定量实验验证生成数据的保真度，然后使用这些生成的数据集对现有 TSCD 算法进行基准测试。 CausalTime为在实际应用中评估TSCD算法提供了可行的解决方案，并且可以推广到广泛的领域。
   
### GAFormer: Enhancing Timeseries Transformers Through Group-Aware Embeddings
 - [[paper](https://openreview.net/attachment?id=c56TWtYp0W&name=pdf)]
 - 分析多元时间序列在许多领域都很重要。 然而，由于复杂的通道间关系和动态变化，很难在多元数据集中学习鲁棒且可概括的表示。 在本文中，我们介绍了一种学习时空结构的新方法，并用它来改进变压器在时间序列数据集上的应用。 我们的框架学习一组组标记，并构建一个特定于实例的组嵌入（GE）层，该层将输入标记分配给少量组标记，以将结构纳入学习中。 然后，我们引入了一种新颖的架构，GroupAware transFormer (GAFormer)，它结合了空间和时间组嵌入，以在许多时间序列分类和回归任务上实现最先进的性能。 在对许多不同时间序列数据集的评估中，我们表明 GE 本身可以为许多主干提供很好的增强，并且通过耦合空间和时间组嵌入，GAFormer 可以超越现有的基线。 最后，我们展示了我们的方法如何在没有有关通道空间排序的信息的情况下识别数据中的潜在结构，并对复杂多元数据集底层的空间和时间结构进行更可解释的分解。

### SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series
 - [[paper](https://openreview.net/attachment?id=s9z0HzWJJp&name=pdf)]
 - 我们推出了 SocioDojo，这是一个开放式的终身学习环境，用于开发可立即部署的自主代理，能够对经济、金融、政治和文化等社会主题进行类似人类的分析和决策。 它由（1）来自新闻、社交媒体、报告等的信息源组成，（2）由书籍、期刊和百科全书构建的知识库，加上互联网和知识图谱搜索接口的工具箱，（3）30K高 -金融、经济、社会和民意调查中的高质量时间序列，支持一项名为“超级投资组合”的新颖任务，该任务可以可靠且可扩展地评估代理人的社会分析和决策能力，其灵感来自于以时间序列为资产的投资组合优化 “投资”。 我们还为超级投资组合任务提出了一种新颖的分析师助理-执行器架构，以及对输入新闻、文章等进行深入分析以协助决策的假设和证明提示。 我们进行实验和消融研究来探索影响性能的因素。 结果表明，与两个实验设置中最先进的方法相比，我们提出的方法实现了 32.4% 和 30.4% 的改进。
   
### Inherently Interpretable Time Series Classification via Multiple Instance Learning
 - [[paper](https://openreview.net/attachment?id=xriGRsoAza&name=pdf)]
 - 传统的时间序列分类 (TSC) 方法通常是黑匣子，模糊了对其决策过程的固有解释。 在这项工作中，我们利用多实例学习（MIL）来克服这个问题，并提出了一个名为 **MILLET** 的新框架：用于局部可解释时间序列分类的多实例学习。 我们将 MILLET 应用于现有的深度学习 TSC 模型，并展示它们如何在不影响（在某些情况下甚至提高）预测性能的情况下变得本质上可解释。 我们在 85 个 UCR TSC 数据集上评估了 MILLET，并提出了一个专门为促进可解释性评估而设计的新颖的合成数据集。 在这些数据集上，我们表明 MILLET 可以快速生成稀疏解释，其质量比其他众所周知的可解释性方法更高。 据我们所知，我们与 MILLET 的合作是第一个为 TSC 开发通用 MIL 方法并将其应用于广泛的领域的工作

### FITS: Modeling Time Series with 10k Parameters
 - [[paper](https://openreview.net/attachment?id=bWcnvZ3qMb&name=pdf)]
 - [[code](https://anonymous.4open.science/r/FITS/README.md)]
 - 在本文中，我们介绍了 **FITS**，一种轻量级但功能强大的时间序列分析模型。 与直接处理原始时域数据的现有模型不同，FITS 的运行原理是可以通过复杂频域中的插值来操纵时间序列，从而实现与时间序列预测和异常检测的最先进模型相媲美的性能 任务。 值得注意的是，FITS 通过大约 10k 参数的精简配置来实现这一目标，使其非常适合边缘设备，并为广泛的应用铺平了道路。

### ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis
 - [[paper](https://openreview.net/attachment?id=vpJMJerXHU&name=pdf)]
 - 近年来，基于 Transformer 和 MLP 的模型迅速崛起，并在时间序列分析中占据主导地位。 相比之下，卷积现在由于性能较差而在时间序列任务中失去动力。 本文研究了如何在时间序列分析中更好地使用卷积这一悬而未决的问题，并努力将卷积带回时间序列分析的舞台。 为此，我们对传统的TCN进行现代化改造，并进行时间序列相关的修改，使其更适合时间序列任务。 作为结果，我们提出了 ModernTCN，并通过时间序列社区中很少探索的方式成功解决了这个悬而未决的问题。 作为纯卷积结构，ModernTCN 在五个主流时间序列分析任务（长期和短期预测、插补、分类和异常检测）上仍然实现了一致的 state-of-the-art 性能，同时保持了基于卷积的效率优势 模型，因此比最先进的基于 Transformer 和 MLP 的模型提供了更好的效率和性能平衡。 我们的研究进一步表明，与之前基于卷积的模型相比，我们的 ModernTCN 具有更大的有效感受野（ERF），因此可以更好地释放卷积在时间序列分析中的潜力。

### Leveraging Generative Models for Unsupervised Alignment of Neural Time Series Data
 - [[paper](https://openreview.net/attachment?id=9zhHVyLY4K&name=pdf)]
 - 我们提出了 STanHop-Net（稀疏串联 Hopfield 网络），用于具有内存增强功能的多元时间序列预测。 我们方法的核心是 STanHop，一种新型的基于 Hopfield 的神经网络模块，其大规模推理模型广泛用于神经科学中，以从高维神经记录中提取潜在表示。 由于会话和动物之间的统计异质性，从头开始训练新模型以推断每个新数据集的潜在动态。 这在计算上是昂贵的并且不能充分利用所有可用数据。 此外，随着这些模型变得越来越复杂，训练它们可能会变得具有挑战性。 与此同时，在机器学习社区中使用预训练模型进行少量镜头和迁移学习也变得越来越普遍。 阻碍神经科学中生成模型重复使用的一个主要障碍是动物体内和动物之间神经动力学的复杂时空结构。 有趣的是，从同一任务的不同数据集确定的潜在动态在质量上是相似的。 在这项工作中，我们利用这一观察结果，提出了一种无源且无监督的对齐方法，该方法利用学习到的动态并能够重复使用经过训练的生成模型。 我们验证了我们的模拟方法，并展示了在完成任务期间获得的运动皮层神经记录对齐的有效性。arsely 以数据依赖的方式学习和存储时间和跨系列表示。 本质上，STanHop 使用两个串联稀疏 Hopfield 层顺序学习时间表示和跨系列表示。 此外，StanHop 还包含两个额外的外部内存模块：即插即用模块和调谐即用模块，分别用于无训练和任务感知内存增强。 它们使 StanHop-Net 能够快速响应某些突发事件。 在方法上，我们通过以分层方式堆叠 STanHop 块来构建 StanHop-Net，从而实现具有特定于分辨率的稀疏性的多分辨率特征提取。 理论上，我们引入了现代 Hopfield 模型的稀疏扩展（广义稀疏现代 Hopfield 模型），并表明与密集模型相比，它在不牺牲记忆容量的情况下赋予了更严格的记忆检索错误。 根据经验，我们验证了我们的框架在合成和现实环境中的有效性。
 
## Miscellaneous
### Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data
 - [[paper](https://openreview.net/attachment?id=4VIgNuQ1pY&name=pdf)]
 - 现实世界时间序列数据中不规则的采样间隔和缺失值对假设间隔一致和完整数据的传统方法提出了挑战。 神经常微分方程（神经 ODE）提供了一种替代方法，利用神经网络与 ODE 求解器相结合，通过参数化向量场学习连续潜在表示。 神经
随机微分方程（神经 SDE）通过合并扩散项来扩展神经 ODE，尽管这种添加并非微不足道，特别是在处理不规则间隔和缺失值时。 因此，仔细设计漂移和扩散函数对于保持稳定性和增强性能至关重要，而不谨慎的选择可能会导致不利的特性，例如缺乏强解、随机不稳定或不稳定的欧拉离散化，从而显着影响神经 SDE 的性能。 在本研究中，我们提出了三类稳定的神经 SDE：Langevin 型 SDE、线性噪声 SDE 和几何 SDE。 然后，我们严格证明了它们在分布变化下保持优异性能的鲁棒性，同时有效防止过度拟合。 为了评估我们方法的有效性，我们对用于插值、预测和分类任务的四个基准数据集进行了广泛的实验，并使用 30 个公共数据集在不同缺失率下分析了我们方法的稳健性。 我们的结果证明了所提出的方法在处理现实世界不规则时间序列数据方面的有效性。

### Conditional Information Bottleneck Approach for Time Series Imputation
 - [[paper](https://openreview.net/attachment?id=K1mcPiDdOJ&name=pdf)]
 - 时间序列插补提出了重大挑战，因为它需要从部分观察的时间序列数据中捕获潜在的时间动态。 在基于生成模型的插补方法最近取得的成功中，信息瓶颈（IB）框架为多重插补提供了非常合适的理论基础，使我们能够解释与插补值相关的不确定性。 然而，直接将 IB 框架应用于时间序列数据而不考虑其时间上下文可能会导致时间依赖性的大量损失，这反过来又会降低整体插补性能。 为了解决这一挑战，我们提出了一种新颖的时间序列插补条件信息瓶颈（CIB）方法，其目的是通过专注于减少基于时间上下文的冗余信息来减轻正则化约束的潜在负面后果。 我们通过采用变分分解对其效果进行了理论分析。 我们利用由此产生的见解，提出了一种新颖的深度学习方法，该方法可以近似实现所提出的时间序列插补的 CIB 目标，作为证据下界和新颖的时间内核增强对比优化的组合。 我们在多个真实世界数据集上进行的实验一致证明，我们的方法显着提高了插补性能（包括插值和外推），并且还增强了基于插补值的预测性能。

# [Publications in NeuIPS 2023](https://nips.cc/Conferences/2023/Schedule)

## Accept domain statistics
 - **[Time Series Forecasting: 10](#time-series-forecasting)**
 - **[Time Series Representation Learning: 3](#time-series-representation-learning)**
 - **[Time Series Generative Learning: 3](#time-series-generative-earning)**
 - **[Time Series Analysis: 9](#time-series-analysis)**
 - **[Miscellaneous:5](#miscellaneous)**
  
## Time Series Forecasting
### Improving *day-ahead* Solar Irradiance Time Series Forecasting by Leveraging Spatio-Temporal Context
- [[paper](https://openreview.net/pdf?id=x5ZruOa4ax)]
- [[code](https://github.com/gitbooo/CrossViVit)]
- 太阳能在通过大幅减少二氧化碳排放来缓解气候变化方面具有巨大潜力。 尽管如此，太阳辐照度固有的可变性对将太阳能无缝集成到电网提出了重大挑战。 虽然大多数先前的研究都集中于采用纯粹基于时间序列的方法进行太阳预报，但只有有限数量的研究考虑了云层覆盖或周围物理环境等因素。 在本文中，我们提出了一种深度学习架构，旨在利用卫星数据利用时空背景，为任何给定站点实现高精度的日前时间序列预测，特别强调预测全球水平辐照度（GHI） 。 我们还提出了一种提取每个时间步预测的分布的方法，这可以作为预测附加的不确定性的非常有价值的度量。 在评估模型时，我们提出了一种测试方案，将特别困难的示例与简单的示例分开，以便捕获关键情况下的模型性能，在本研究中，这些情况是遭受不同多云条件的日子。 此外，我们提出了一个新的多模式数据集，收集来自多个地理位置不同的太阳站的大区域和时间序列的太阳辐照度和其他相关物理变量的卫星图像。 我们的方法在太阳辐照度预测方面表现出强大的性能，包括在未观测的太阳能站进行的零样本泛化测试，并在促进太阳能有效并入电网方面具有巨大的前景

### BasisFormer: Attention-based Time Series Forecasting with Learnable and Interpretable Basis
- [[paper](https://arxiv.org/pdf/2310.20496.pdf)]
- [[code](https://github.com/nzl5116190/Basisformer)]
- 由于它们能够充当特征提取器或未来参考，因此基础已成为基于深度学习的现代时间序列预测模型不可或缺的一部分。 为了有效，基础必须针对特定的时间序列数据集进行定制，并与该集中的每个时间序列表现出明显的相关性。 然而，当前最先进的方法在同时满足这两个要求的能力方面受到限制。 为了应对这一挑战，我们提出了 BasisFormer，这是一种利用可学习和可解释基础的端到端时间序列预测架构。 该架构由三个组成部分组成：首先，我们通过自适应自监督学习获取基础，它将时间序列的历史部分和未来部分视为两种不同的视图，并采用对比学习。 接下来，我们设计一个 Coef 模块，通过双向交叉注意力计算历史视图中时间序列和基数之间的相似性系数。 最后，我们提出了一个预测模块，它根据相似系数选择并巩固未来视图中的基础，从而产生准确的未来预测。 通过对六个数据集的广泛实验，我们证明 BasisFormer 在单变量和多变量预测任务上分别比之前最先进的方法高出 11.04% 和 15.78%
  
### WITRAN: Water-wave Information Transmission and Recurrent Acceleration Network for Long-range Time Series Forecasting
- [[paper](https://openreview.net/pdf?id=y08bkEtNBK)]
- [[code](https://github.com/Water2sea/WITRAN)]
- 捕获语义信息对于准确的长期时间序列预测至关重要，这涉及对全局和局部相关性进行建模，以及发现长期和短期重复模式。 以前的工作已经部分地分别解决了这些问题，但未能同时解决所有问题。 与此同时，它们的时间和内存复杂性对于长期预测来说仍然不够低。 为了解决捕获不同类型语义信息的挑战，我们提出了一种新颖的水波信息传输（WIT）框架。 该框架通过双粒度信息传输捕获长期和短期重复模式。 它还通过使用水平垂直门控选择单元 (HVGSU) 递归地融合和选择信息来对全局和局部相关性进行建模。 此外，为了提高计算效率，我们提出了一种通用的循环加速网络（RAN），它将时间复杂度降低到 O(√L)，同时保持内存复杂度为 O(L)。 我们提出的方法称为水波信息传输和循环加速网络（WITRAN），在远程和超远程时间序列预测任务上分别优于最先进的方法 5.80% 和 14.28%， 正如四个基准数据集的实验所证明的。

### Conformal PID Control for Time Series Prediction
- [[paper](https://openreview.net/pdf?id=zPYeYv6YYs)]
- [[code](https://github.com/aangelopoulos/conformal-time-series)]
- 我们研究时间序列预测的不确定性量化问题，目标是提供具有形式保证的易于使用的算法。 我们提出的算法建立在共形预测和控制理论的思想之上，能够在在线环境中前瞻性地对共形分数进行建模，并适应由于季节性、趋势和一般分布变化而出现的系统误差。 我们的理论既简化又加强了在线共形预测的现有分析。 对美国全州范围内的 COVID-19 死亡人数进行提前 4 周预测的实验表明，与 CDC 官方通信中使用的集合预报器相比，其覆盖范围有所改善。 我们还使用自回归、Theta、Prophet 和 Transformer 模型进行了预测电力需求、市场回报和温度的实验。
  
### Frequency-domain MLPs are More Effective Learners in Time Series Forecasting
- [[paper](https://arxiv.org/pdf/2311.06184.pdf)]
- [[code](https://github.com/aikunyi/FreTS)]
- 时间序列预测在金融、交通、能源、医疗保健等不同行业中发挥着关键作用。 虽然现有文献设计了许多基于 RNN、GNN 或 Transformer 的复杂架构，但提出了另一种基于多层感知器（MLP）的方法，其结构简单、复杂度低且性能优越。 然而，大多数基于MLP的预测方法都存在逐点映射和信息瓶颈，这在很大程度上阻碍了预测性能。 为了克服这个问题，我们探索了在频域中应用 MLP 进行时间序列预测的新方向。 我们研究了频域 MLP 的学习模式，发现了它们有利于预测的两个固有特征：（i）全局视图：频谱使 MLP 拥有完整的信号视图并更容易学习全局依赖性，以及（ii）能量压缩：频率 域 MLP 集中于信号能量紧凑的频率分量的较小关键部分。 然后，我们提出了 FreTS，这是一种基于频域 MLP 的简单而有效的架构，用于时间序列预测。 FreTS主要涉及两个阶段，（i）域转换，将时域信号转换为频域复数； (ii) 频率学习，执行我们重新设计的 MLP，以学习频率分量的实部和虚部。 上述在系列间和系列内尺度上运行的阶段进一步有助于通道方面和时间方面的依赖性学习。 对 13 个现实世界基准（包括 7 个短期预测基准和 6 个长期预测基准）进行的广泛实验证明了我们相对于最先进方法的一贯优势
  
### Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting
- [[paper](https://arxiv.org/pdf/2307.11494.pdf)]
- [[code](https://github.com/amazon-science/unconditional-time-series-diffusion)]
- 扩散模型在各个领域的生成建模任务中取得了最先进的性能。 先前关于时间序列扩散模型的工作主要集中于开发针对特定预测或插补任务的条件模型。 在这项工作中，我们探索了任务无关的无条件扩散模型在多个时间序列应用中的潜力。 我们提出了 TSDiff，一种无条件训练的时间序列扩散模型。 我们提出的自引导机制能够在推理过程中为下游任务调节 TSDiff，而不需要辅助网络或改变训练程序。 我们证明了我们的方法在三个不同时间序列任务上的有效性：预测、细化和合成数据生成。 首先，我们证明 TSDiff 与几种特定于任务的条件预测方法（预测）相比具有竞争力。 其次，我们利用学习到的 TSDiff 隐式概率密度来迭代地细化基本预测器的预测，从而减少反向扩散（细化）的计算开销。 值得注意的是，该模型的生成性能保持不变 - 使用 TSDiff 的合成样本进行训练的下游预测器优于使用其他最先进的生成时间序列模型的样本进行训练的预测器，有时甚至优于使用真实数据训练的模型（合成 ）。
  
### FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective
- [[paper](https://arxiv.org/pdf/2311.06190.pdf)]
- [[code](https://github.com/aikunyi/FourierGNN)]
- 多元时间序列 (MTS) 预测在许多行业中表现出非常重要的作用。 当前最先进的基于图神经网络（GNN）的预测方法通常需要图网络（例如 GCN）和时间网络（例如 LSTM）来捕获系列间（空间）动态和系列内（ 分别是时间）依赖性。 然而，两个网络的不确定兼容性给手工模型设计带来了额外的负担。 此外，分离的时空建模自然违反了现实世界中统一的时空相互依赖关系，这在很大程度上阻碍了预测性能。 为了克服这些问题，我们探索了直接应用图网络的有趣方向，并从纯图的角度重新思考 MTS 预测。 我们首先定义了一种新颖的数据结构——超变量图，它将每个序列值（无论变量或时间戳）视为图节点，并将滑动窗口表示为时空全连接图。 该观点统一考虑时空动力学，并将经典 MTS 预测重新表述为超变量图的预测。 然后，我们提出了一种新颖的架构傅里叶图神经网络（FourierGNN），通过堆叠我们提出的傅里叶图运算符（FGO）来在傅里叶空间中执行矩阵乘法。 FourierGNN 具有足够的表达能力并实现了较低的复杂度，可以有效且高效地完成预测。 此外，我们的理论分析揭示了 FGO 在时域上与图卷积的等价性，这进一步验证了 FourierGNN 的有效性。 对七个数据集的广泛实验证明了与最先进的方法相比，我们具有更高的效率和更少的参数的卓越性能。

### OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling
 - [[paper](https://arxiv.org/pdf/2309.12659.pdf)]
 - [[code](https://github.com/yfzhang114/OneNet)]
 - 时间序列预测模型在线更新旨在通过基于流数据高效更新预测模型来解决概念漂移问题。 许多算法都是为在线时间序列预测而设计的，其中一些算法利用交叉变量依赖性，而另一些则假设变量之间的独立性。 鉴于每个数据假设在在线时间序列建模中都有其自身的优点和缺点，我们提出了在线集成网络（OneNet）。 它动态更新和组合两个模型，一个专注于跨时间维度的依赖关系建模，另一个专注于跨变量依赖关系建模。 我们的方法将基于强化学习的方法融入到传统的在线凸编程框架中，允许动态调整权重的两个模型的线性组合。 OneNet 解决了经典在线学习方法的主要缺点，即适应概念漂移的速度往往较慢。 实证结果表明，与 State-Of-The-Art (SOTA) 方法相比，OneNet 将在线预测误差降低了 50% 以上。
   
### Adaptive Normalization for Non-stationary Time Series Forecasting: A Temporal Slice Perspective
 - [[paper](https://openreview.net/pdf?id=5BqDSw8r5j)]
 - [[code](https://github.com/icantnamemyself/SAN)]
 - 深度学习模型由于其捕获序列依赖性的强大能力而逐渐提高了时间序列预测的性能。 然而，由于现实世界数据存在非平稳性，即数据分布随着时间的推移而快速变化，做出准确的预测仍然具有挑战性。 为了缓解这种困境，人们做出了一些努力，通过标准化操作来减少非平稳性。 然而，这些方法通常忽略了输入序列和水平序列之间的分布差异，并假设同一实例内的所有时间点具有相同的统计属性，这过于理想，可能导致相对改进不理想。 为此，我们提出了一种新颖的切片级自适应归一化（SAN），这是一种通过更灵活的归一化和反归一化来增强时间序列预测的新方案。 SAN 包括两个关键设计。 首先，SAN 试图消除以局部时间片（即子序列）为单位而不是全局实例的时间序列的非平稳性。 其次，SAN采用轻微的网络模块来独立建模原始时间序列统计特性的演变趋势。 因此，SAN 可以作为通用的模型无关插件，更好地减轻时间序列数据非平稳特性的影响。 我们在四种广泛使用的预测模型上实例化了所提出的 SAN，并在基准数据集上测试它们的预测结果以评估其有效性。 此外，我们还报告了一些富有洞察力的发现，以深入分析和理解我们提出的 SAN

### Conformal Prediction for Time Series with Modern Hopfield Networks
 - [[paper](https://arxiv.org/pdf/2303.12783.pdf)]
 - [[code](https://github.com/ml-jku/HopCPT)]
 - 为了量化不确定性，共形预测方法越来越受到人们的关注，并已成功应用于各个领域。 然而，它们很难应用于时间序列，因为时间序列的自相关结构违反了共形预测所需的基本假设。 我们提出了 HopCPT，一种新颖的时间序列保形预测方法，它不仅可以处理时间结构，而且可以利用它们。 我们表明，我们的方法在理论上对于存在时间依赖性的时间序列是合理的。 在实验中，我们证明我们的新方法在来自四个不同领域的多个真实世界时间序列数据集上优于最先进的保形预测方法

## Time Series Representation Learning
### FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space
- [[paper](https://arxiv.org/pdf/2310.20071.pdf)]
- [[code](https://github.com/tomoyoshki/focal)]
- 本文提出了一种新颖的对比学习框架，称为 FOCAL，用于通过自监督训练从多模态时间序列传感信号中提取综合特征。 现有的多模态对比框架主要依赖于感觉模态之间的共享信息，但没有明确考虑对于理解底层传感物理至关重要的排他模态信息。 此外，时间序列的对比框架没有适当地处理时间信息局部性。 FOCAL 通过做出以下贡献来解决这些挑战：首先，给定多模态时间序列，它将每种模态编码到由彼此正交的共享特征和私有特征组成的分解潜在空间中。 共享空间通过模态匹配目标强调跨感官模态一致的特征模式。 相反，私人空间通过变换不变的目标提取模态专有信息。 其次，我们提出了模态特征的时间结构约束，使得时间相邻样本之间的平均距离不大于时间遥远样本的平均距离。 对具有两个骨干编码器和两个分类器的四个多模态传感数据集进行了广泛的评估，以证明 FOCAL 的优越性。 在不同比例的可用标签下，它始终优于下游任务中最先进的基线，并具有明显的优势
  
### Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series
- [[paper](https://arxiv.org/pdf/2310.14017.pdf)]
- [[code](https://github.com/DL4mHealth/COMET)]
- 对比表示学习在医学时间序列分析中至关重要，因为它减轻了对劳动密集型、特定领域和稀缺专家注释的依赖。 然而，现有的对比学习方法主要集中于单一数据级别，无法充分利用医疗时间序列的复杂性。 为了解决这个问题，我们提出了 COMET，这是一种创新的分层框架，它利用医疗时间序列中所有固有级别的数据一致性。 我们精心设计的模型系统地捕获了四个潜在级别的数据一致性：观察、样本、试验和患者级别。 通过在多个级别上开发对比损失，我们可以学习有效的表示，以保持全面的数据一致性，以自我监督的方式最大化信息利用率。 我们在具有挑战性的独立于患者的环境中进行实验。 我们使用三个不同的数据集将 COMET 与六个基线进行比较，其中包括心肌梗塞的心电图信号以及阿尔茨海默病和帕金森病的脑电图信号。 结果表明，COMET 始终优于所有基线，特别是在所有数据集中使用 10% 和 1% 标记数据分数的设置中。 这些结果强调了我们的框架在推进医学时间序列对比表示学习技术方面的重大影响
  
### Finding Order in Chaos: A Novel Data Augmentation Method for Time Series in Contrastive Learning
- [[paper](https://arxiv.org/pdf/2309.13439.pdf)]
- [[code](https://github.com/eth-siplab/Finding_Order_in_Chaos)]
- 众所周知，对比学习的成功取决于数据增强。 尽管通过在视觉等某些领域利用预定义技术可以很好地控制数据增强的程度，但由于数据生成机制的复杂性（例如复杂的机制），时间序列数据增强的探索较少，并且仍然是一个具有挑战性的问题 参与心血管系统。 此外，还没有广泛认可的通用时间序列增强方法可以应用于不同的任务。 在本文中，我们提出了一种用于准周期时间序列任务的新型数据增强方法，旨在将类内样本连接在一起，从而在潜在空间中找到顺序。 我们的方法建立在众所周知的混合技术的基础上，通过结合一种新颖的方法来解释非平稳时间序列的周期性。 此外，通过控制数据增强产生的混乱程度，我们的方法可以改进下游任务的特征表示和性能。 我们在三个时间序列任务上评估我们提出的方法，包括心率估计、人类活动识别和心血管疾病检测。 针对最先进方法的大量实验表明，所提出的方法在这三个任务中优于最佳数据生成和已知数据增强技术的先前工作，反映了所提出方法的有效性。

## Time Series Generative Learning
### Large Language Models Are Zero-Shot Time Series Forecasters
- [[paper](https://arxiv.org/pdf/2310.07820.pdf?trk=public_post_comment-text)]
- [[code](https://github.com/ngruver/llmtime)]
- 通过将时间序列编码为一串数字，我们可以将时间序列预测构建为文本中的下一个标记预测。 在开发这种方法时，我们发现 GPT-3 和 LLaMA-2 等大型语言模型 (LLM) 可以令人惊奇地以零样本推断时间序列，其水平相当于或超过在下游任务上训练的专用时间序列模型的性能。 为了促进这种性能，我们提出了有效标记时间序列数据并将标记上的离散分布转换为连续值上的高度灵活的密度的程序。 我们认为时间序列法学硕士的成功源于它们自然地表示多模态分布的能力，再加上简单性和重复性的偏差，这与许多时间序列中的显着特征相一致，例如重复的季节性趋势。 我们还展示了法学硕士如何自然地处理缺失数据，而无需通过非数字文本进行插补，容纳文本辅助信息，并回答问题以帮助解释预测。 虽然我们发现增加模型大小通常会提高时间序列的性能，但我们表明 GPT-4 的性能可能比 GPT-3 差，因为它对数字进行标记的方式以及较差的不确定性校准，这可能是 RLHF 等对齐干预的结果。
  
### One Fits All: Power General Time Series Analysis by Pretrained LM
- [[paper](https://www.researchgate.net/profile/Tian-Zhou-18/publication/368753168_One_Fits_AllPower_General_Time_Series_Analysis_by_Pretrained_LM/links/647d80e3b3dfd73b77662460/One-Fits-AllPower-General-Time-Series-Analysis-by-Pretrained-LM.pdf)]
- 尽管我们见证了预训练模型在自然语言处理（NLP）和计算机视觉（CV）领域取得的巨大成功，但在一般时间序列分析方面取得的进展有限。 与 NLP 和 CV 中统一的模型可以用于执行不同的任务不同，专门设计的方法在分类、异常检测、预测和小样本学习等每个时间序列分析任务中仍然占主导地位。 阻碍时间序列分析预训练模型开发的主要挑战是缺乏大量训练数据。 在这项工作中，我们通过利用从数十亿个代币中预先训练的语言或 CV 模型进行时间序列分析来应对这一挑战。 具体来说，我们避免改变预训练语言或图像模型中残差块的自注意力和前馈层。 该模型称为 Frozen Pretrained Transformer (FPT)，通过对涉及时间序列的所有主要类型任务进行微调来进行评估。 我们的结果表明，自然语言或图像的预训练模型可以在所有主要时间序列分析任务中产生可比较的或最先进的性能，如图 1 所示。我们还从理论上和经验上发现， 自注意力模块的行为与主成分分析（PCA）类似，这种观察有助于解释 Transformer 如何弥合域差距，也是理解预训练 Transformer 通用性的关键一步。
  
### On the Constrained Time-Series Generation Problem
- [[paper](https://arxiv.org/pdf/2307.01717.pdf)]
- 合成时间序列在实际应用中经常用于增强历史时间序列数据集，以提高机器学习算法的性能，放大罕见事件的发生，并创建时间序列描述的反事实场景。 分布相似性（我们称之为真实性）以及满足某些数值约束是反事实时间序列场景生成请求中的常见要求。 例如，美联储发布了由金融机构受限时间序列给出的综合市场压力情景，以评估其在假设衰退中的表现。 现有的生成约束时间序列的方法通常会惩罚训练损失以强制执行约束，并拒绝不合格的样本。 然而，如果我们改变约束，这些方法将需要重新训练，并且拒绝采样的计算成本可能很高，或者对于复杂的约束来说是不切实际的。 在本文中，我们提出了一套新颖的方法来解决约束时间序列生成问题，并提供有效的采样，同时确保生成的时间序列的真实性。 特别是，我们使用约束优化框架来构建问题，然后提出一组生成方法，包括“GuidedDiffTime”，这是一种用于生成真实时间序列的引导扩散模型。 根据经验，我们评估了我们在金融和能源数据的多个数据集上的工作，其中纳入约束至关重要。 我们表明，我们的方法在质量和数量上都优于现有的工作。 最重要的是，我们表明，我们的“GuidedDiffTime”模型是唯一不需要针对新约束进行重新训练的解决方案，从而显着减少碳足迹，最多减少 92%。 现有的深度学习方法。

## Time Series Anomaly
### Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction
- [[paper](https://arxiv.org/pdf/2310.15416.pdf)]
- [[code](https://github.com/andrewlai61616/NPSR)]
- 由于可能发生的模式的复杂性和多样性，时间序列异常检测具有挑战性。 一个主要困难来自对时间相关关系进行建模以发现上下文异常，同时保持点异常检测的准确性。 在本文中，我们提出了一种利用基于点和基于序列的重建模型的无监督时间序列异常检测框架。 基于点的模型尝试量化点异常，基于序列的模型尝试量化点异常和上下文异常。 根据观测时间点是与名义时间点的两阶段偏差值的公式，我们引入了根据重建误差的组合值的比率计算的名义分数。 我们通过进一步整合名义分数和异常分数得出诱导异常分数，然后从理论上证明在一定条件下诱导异常分数相对于原始异常分数的优越性。 对多个公共数据集进行的广泛研究表明，所提出的框架优于大多数最先进的时间序列异常检测基线。
  
### Drift doesn't Matter: Dynamic Decomposition with Diffusion Reconstruction for Unstable Multivariate Time Series Anomaly Detection
- [[paper](https://openreview.net/pdf?id=aW5bSuduF1)]
- [[code](https://github.com/ForestsKing/D3R)]
- 最近提出了许多无监督方法用于多元时间序列异常检测。 然而，现有的工作主要关注稳定数据，而常常忽略非平稳环境产生的漂移，这可能导致大量误报。 我们提出了动态分解与扩散重建（D3R），这是一种针对现实世界不稳定数据的新型异常检测网络，以填补这一空白。 D3R 通过分解和重构来解决漂移问题。 在分解过程中，我们利用数据时间混合注意力来动态分解长周期多元时间序列，克服了局部滑动窗口的限制。 信息瓶颈在重建过程中是关键且难以确定的。 为了避免一旦瓶颈发生变化就重新训练，我们通过噪声扩散从外部控制它并直接重建污染的数据。 整个模型可以进行端到端的训练。 对各种真实世界数据集的大量实验表明，D3R 显着优于现有方法，比之前的 SOTA 模型平均相对提高了 11%。
  
### MEMTO: Memory-guided Transformer for Multivariate Time Series Anomaly Detection
 - [[paper](https://arxiv.org/pdf/2312.02530.pdf)]
 - 由于复杂的时间依赖性和变量间的相关性，检测现实世界的多元时间序列数据中的异常具有挑战性。 最近，基于重建的深度模型已被广泛用于解决该问题。 然而，这些方法仍然存在过度泛化的问题，并且无法提供一致的高性能。 为了解决这个问题，我们提出了 MEMTO，一种使用基于重建方法的记忆引导 Transformer。 它被设计成包含一种新颖的内存模块，该模块可以学习每个内存项应响应输入数据而更新的程度。 为了稳定训练过程，我们使用两阶段训练范例，其中涉及使用 K 均值聚类来初始化内存项。 此外，我们引入了一种基于偏差的二维检测标准，该标准考虑输入空间和潜在空间来计算异常分数。 我们在来自不同领域的五个真实世界数据集上评估了我们提出的方法，它的平均异常检测 F1 分数为 95.74%，显着优于以前的最先进方法。 我们还进行了广泛的实验，以实证验证我们提出的模型关键组件的有效性
  
## Time Series Analysis
### Sparse Graph Learning from Spatiotemporal Time Series
- [[paper](https://www.jmlr.org/papers/volume24/22-1154/22-1154.pdf)]
- [[code](https://github.com/andreacini/sparse-graph-learning)]
- 图神经网络在时空时间序列分析方面的杰出成就表明，关系约束将有效的归纳偏差引入神经预测架构中。 然而，通常，表征底层数据生成过程的关系信息是不可用的，并且实践者面临从数据推断在后续处理阶段使用哪个关系图的问题。 我们提出了新颖、有原则但又实用的基于概率评分的方法，该方法将关系依赖性学习为图上的分布，同时最大化任务的端到端性能。 所提出的图学习框架基于用于基于蒙特卡罗分数的梯度估计的综合方差减少技术，具有理论基础，并且正如我们所表明的，在实践中有效。 在本文中，我们重点关注时间序列预测问题，并表明，通过针对图学习问题定制梯度估计器，我们能够在控制学习图的稀疏性和 计算可扩展性。 我们根据经验评估了所提出的方法在综合和现实世界基准上的有效性，表明所提出的解决方案可以用作独立的图识别过程以及端到端预测架构的图学习组件。
  
### Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency
- [[paper](https://arxiv.org/pdf/2306.02109.pdf)]
- [[code](https://github.com/mims-harvard/TimeX)]
- 解释时间序列模型具有独特的挑战性，因为它需要识别驱动模型预测的时间序列信号的位置及其与可解释时间模式的匹配。 虽然来自其他模式的解释器可以应用于时间序列，但它们的归纳偏差不能很好地转移到时间序列固有的挑战性解释上。 我们提出了 TIMEX，一种用于培训解释者的时间序列一致性模型。 TIMEX 训练可解释的代理来模仿预训练时间序列模型的行为。 它通过引入模型行为一致性来解决模型可信度问题，这是一种新颖的公式，可以保留预训练模型引起的潜在空间中的关系与 TIMEX 引起的潜在空间中的关系。 TIMEX 提供离散归因图，与现有的可解释性方法不同，它学习可以以多种方式使用的潜在解释空间，例如提供地标以直观地聚合相似的解释并轻松识别时间模式。 我们在八个合成和真实数据集上评估 TIMEX，并将其性能与最先进的可解释性方法进行比较。 我们还使用生理时间序列进行案例研究。 定量评估表明，与所有数据集的基线相比，TIMEX 在每个指标中都实现了最高或第二高的性能。 通过案例研究，我们表明 TIMEX 的新颖组件显示出训练忠实、可解释的模型的潜力，这些模型可以捕获预训练时间序列模型的行为
  
### Causal Discovery from Subsampled Time Series with Proxy Variables
- [[paper](https://arxiv.org/pdf/2305.05276.pdf)]
- [[code](https://github.com/lmz123321/proxy_causal_discovery)]
- 从时间序列数据推断因果结构是许多科学探究的核心兴趣。 这种推断的一个主要障碍是二次抽样的问题，即测量的频率远低于因果影响的频率。 为了克服这个问题，人们提出了许多方法，但要么仅限于线性情况，要么无法实现可识别性。 在本文中，我们提出了一种基于约束的算法，可以从子采样时间序列中识别整个因果结构，而无需任何参数约束。 我们的观察是，二次采样的挑战主要来自未观察时间步长的隐藏变量。 同时，每个隐藏变量都有一个观察到的代理，它本质上是未来某个可观察时间的代理，受益于时间结构。 基于这些，我们可以利用代理来消除隐藏变量引起的偏差，从而实现可识别性。 遵循这种直觉，我们提出了一种基于代理的因果发现算法。 我们的算法是非参数的，可以实现完全的因果识别。 
  
### ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling
- [[paper](https://openreview.net/pdf?id=YJDz4F2AZu)]
- [[code](https://seqml.github.io/contiformer/)]
- 对不规则时间序列的连续时间动态进行建模对于解释连续发生的数据演变和相关性至关重要。 包括循环神经网络或 Transformer 模型在内的传统方法通过强大的神经架构利用归纳偏差来捕获复杂的模式。 然而，由于其离散特性，它们在推广到连续时间数据范式方面存在局限性。 尽管神经常微分方程（神经常微分方程）及其变体在处理不规则时间序列方面显示出有希望的结果，但它们通常无法捕获这些序列中复杂的相关性。 同时对输入数据点之间的关系进行建模并捕获连续时间系统的动态变化具有挑战性但要求很高。 为了解决这个问题，我们提出了 ContiFormer，它将普通 Transformer 的关系建模扩展到连续时间域，明确地将神经常微分方程的连续动态建模能力与 Transformer 的注意力机制结合起来。 我们从数学上描述了 ContiFormer 的表达能力，并说明，通过函数假设的精心设计，许多专门用于不规则时间序列建模的 Transformer 变体可以作为 ContiFormer 的特例。 对合成数据集和真实数据集进行的广泛实验表明，ContiFormer 对不规则时间序列数据具有卓越的建模能力和预测性能。
  
### SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling
- [[paper](https://arxiv.org/pdf/2302.00861.pdf)]
- [[code](https://github.com/thuml/SimMTM)]
- 时间序列分析有着广泛的应用领域。 最近，为了减少标签费用并有利于各种任务，自监督预训练引起了人们的极大兴趣。 一种主流范式是屏蔽建模，它通过学习基于未屏蔽部分重建屏蔽内容来成功地预训练深度模型。 然而，由于时间序列的语义信息主要包含在时间变化中，随机屏蔽部分时间点的标准方法将严重破坏时间序列的重要时间变化，使得重建任务难以指导表示学习。 因此，我们提出了 SimMTM，一个用于掩蔽时间序列建模的简单预训练框架。 通过将屏蔽建模与流形学习相关联，SimMTM 提出通过流形外部多个邻居的加权聚合来恢复屏蔽时间点，这通过组装多个屏蔽序列中被破坏但互补的时间变化来简化重建任务。 SimMTM 进一步学习揭示流形的局部结构，这有助于掩模建模。 实验上，与最先进的时间序列预训练方法相比，SimMTM 在预测和分类这两个典型时间序列分析任务中实现了最先进的微调性能，涵盖域内和跨域设置

### Neural Lad: A Neural Latent Dynamics Framework for Times Series Modeling
- [[paper](https://openreview.net/pdf?id=bISkJSa5Td)]
- 神经常微分方程（神经 ODE）是一个优雅而强大的框架，用于学习时间序列建模的时间动力学。 然而，我们观察到现有的神经常微分方程预测模型存在两个缺点：i）仅通过对观测信号的局部变化进行线性变换来控制潜在状态可能是不够的； ii) 缺乏捕捉时间序列预测任务固有周期性特性的能力； 为了克服这两个问题，我们引入了一种名为 Neural Lad 的新神经 ODE 框架，这是一种神经潜在动力学模型，其中潜在表示随着观测信号和季节性趋势特征的变化而增强的 ODE 不断演化。 我们以基于注意力的方式将输入信号的局部变化合并到潜在动态中，并设计基于基础扩展的残差架构来描述底层动态中的周期性。 为了适应多变量时间序列预测，我们通过学习多个时间序列之间的自适应关系来扩展 Neural Lad。 实验表明，我们的模型可以在各种数据集中与现有的神经 ODE 系列和变换器变体相比实现更好或相当的性能。 值得注意的是，Neural Lad 的经验优势在单变量和多变量不规则采样时间序列的短期和长期预测中是一致的

### Time Series Kernels based on Nonlinear Vector AutoRegressive Delay Embeddings
- [[paper](https://openreview.net/pdf?id=UBUWFEwn7p)]
- [[code](https://github.com/gdefe/nvark-kernel)]
- 核设计是时间序列分析的一个关键但具有挑战性的方面，特别是在小数据集的背景下。 近年来，油藏计算（RC）已成为一种强大的工具，可以根据生成过程的基本动态而不是观测数据来比较时间序列。 然而，RC 的性能高度依赖于超参数设置，由于 RC 的循环性质，超参数设置难以解释且优化成本高昂。 在这里，我们基于最近建立的油藏动力学和非线性向量自回归（NVAR）过程之间的等价性，提出了一个新的时间序列内核。 内核是非循环的，并且依赖于一小组有意义的超参数，为此我们建议采用有效的启发式方法。 我们在各种现实世界的分类任务中展示了出色的性能，无论是在准确性还是速度方面。 这进一步加深了对 RC 表示学习模型的理解，并将 NVAR 框架的典型用途扩展到内核设计和现实世界时间序列数据的表示

### Sparse Deep Learning for Time Series Data: Theory and Applications
 - [[paper](https://arxiv.org/pdf/2305.18803.pdf)]
 - [[code](https://github.com/thuml/Koopa)]
 - 稀疏深度学习已成为提高深度神经网络在不确定性量化、变量选择和大规模网络压缩等领域性能的流行技术。 然而，现有的大多数研究都集中在观测值独立同分布（i.i.d.）的问题上，而对于观测值依赖的问题（例如自然语言处理中的时间序列数据和顺序数据）却很少有研究。 本文旨在通过研究具有相关数据的稀疏深度学习理论来解决这一差距。 我们证明稀疏循环神经网络（RNN）可以被一致地估计，并且它们的预测在适当的假设下呈渐近正态分布，从而能够正确量化预测不确定性。 我们的数值结果表明，稀疏深度学习在时间序列数据的预测不确定性量化方面优于最先进的方法，例如共形预测。 此外，我们的结果表明，所提出的方法可以一致地识别时间序列数据的自回归顺序，并且在大规模模型压缩方面优于现有方法。 我们提出的方法在金融、医疗保健和能源等领域具有重要的实际意义，这些领域都关注准确的点估计和预测不确定性量化。

### Koopa: Learning Non-stationary Time Series Dynamics with Koopman Predictors
 - [[paper](https://arxiv.org/pdf/2305.18803.pdf)]
 - [[code](https://github.com/thuml/Koopa)]
 - 由于复杂的时间依赖性和变量间的相关性，检测现实世界的多元时间序列数据中的异常具有挑战性。 最近，基于重建的深度模型已被广泛用于解决该问题。 然而，这些方法仍然存在过度泛化的问题，并且无法提供一致的高性能。 为了解决这个问题，我们提出了 MEMTO，一种使用基于重建方法的记忆引导 Transformer。 它旨在适应真实世界时间序列的特点，即固有的非平稳性，这对深度预测模型提出了主要挑战。 虽然以前的模型因时间分布变化而受到复杂的序列变化的影响，但我们用现代库普曼理论来处理非平稳时间序列，该理论从根本上考虑了潜在的时变动力学。 受描绘复杂动力系统的库普曼理论的启发，我们通过傅立叶滤波器从复杂的非平稳序列中分离出时变和时不变分量，并设计库普曼预测器来推进各自的动力学。 从技术上讲，我们建议 Koopa 作为一种新颖的 Koopman 预测器，由可学习分层动态的可堆叠块组成。 Koopa 寻求 Koopman 嵌入的测量函数，并利用 Koopman 算子作为隐式转换的线性描述。 为了应对表现出较强局部性的时变动态，Koopa 计算时间邻域中的上下文感知算子，并能够利用传入的地面实况来扩大预测范围。 此外，通过将库普曼预测器集成到深度残差结构中，我们阐明了先前库普曼预测器中的约束重建损失，并实现了端到端的预测目标优化。 与最先进的模型相比，Koopa 实现了具有竞争力的性能，同时节省了 77.3% 的训练时间和 76.0% 的内存。它采用了一种新颖的内存模块，可以学习每个内存项应根据输入数据更新的程度。 为了稳定训练过程，我们使用两阶段训练范例，其中涉及使用 K 均值聚类来初始化内存项。 此外，我们引入了一种基于偏差的二维检测标准，该标准考虑输入空间和潜在空间来计算异常分数。 我们在来自不同领域的五个真实世界数据集上评估了我们提出的方法，它的平均异常检测 F1 分数为 95.74%，显着优于以前的最先进方法。 我们还进行了广泛的实验，以实证验证我们提出的模型关键组件的有效性

## Miscellaneous
### CrossGNN: Confronting Noisy Multivariate Time Series Via Cross Interaction Refinement
- [[paper](https://openreview.net/pdf?id=xOzlW2vUYc)]
- [[code](https://github.com/hqh0728/CrossGNN)]
- 近年来，多元时间序列（MTS）预测技术得到了快速发展并在各个领域得到广泛应用。 基于 Transformer 和基于 GNN 的方法由于其对时间和变量交互建模的强大能力而显示出巨大的潜力。 然而，通过对现实世界数据进行全面分析，我们发现现有方法并不能很好地处理变量之间的时间波动和异质性。 为了解决上述问题，我们提出了 CrossGNN，一种线性复杂性 GNN 模型，用于细化 MTS 的跨尺度和跨变量交互。 为了处理时间维度上的意外噪声，利用自适应多尺度标识符（AMSI）来构建降噪的多尺度时间序列。 提出了 Cross-Scale GNN 来提取趋势更清晰、噪声更弱的尺度。 跨变量 GNN 的提出是为了利用不同变量之间的同质性和异质性。 通过同时关注显着性分数较高的边缘并限制分数较低的边缘，CrossGNN 的时间和空间复杂度（即 O(L)）可以与输入序列长度 L 呈线性关系。在 8 个真实世界中进行的广泛实验结果 MTS 数据集证明了 CrossGNN 与最先进方法相比的有效性
  
### WildfireSpreadTS: A dataset of multi-modal time series for wildfire spread prediction
- [[paper](https://openreview.net/pdf?id=RgdGkPRQ03)]
- [[code](https://github.com/SebastianGer/WildfireSpreadTS)]
- 我们提出了一个多时态、多模式遥感数据集，用于以 24 小时的分辨率预测活跃野火的蔓延方式。 该数据集由 2018 年 1 月至 2021 年 10 月美国 607 起火灾事件的 13 607 张图像组成。对于每个火灾事件，该数据集包含每日观测的完整时间序列，其中包含检测到的活跃火灾以及与燃料、地形和火灾相关的变量。 天气状况。 该数据集具有挑战性，因为：a）其输入是多时态的，b）大量的 23 个多模态输入通道，c）高度不平衡的标签和 d）由于烟雾、云和数据中的不准确而产生的噪声标签 主动火灾探测。 物理过程的潜在复杂性增加了这些挑战。 与该领域现有的公共数据集相比，WILDFIRESPREADTS 由于其时间序列结构，可以对蔓延的野火进行多时间建模。 此外，我们还为主动火力图提供额外的输入模式和 375m 的高空间分辨率。 我们发布此数据集是为了鼓励使用多时态、抗噪声或生成方法、不确定性估计或处理高维输入空间的高级优化技术对这项重要任务进行进一步研究
  
### BioMassters: A Benchmark Dataset for Forest Biomass Estimation using Multi-modal Satellite Time-series
- [[paper](https://openreview.net/pdf?id=hrWsIC4Cmz)]
- [[code](https://nascetti-a.github.io/BioMasster/)]
- 地上生物量是一个重要的变量，因为森林在缓解气候变化方面发挥着至关重要的作用，因为它们充当高效、自然和具有成本效益的碳汇。 传统的现场和机载激光雷达测量已被证明可以提供可靠的森林生物量估计。 然而，大规模使用这些技术可能具有挑战性且成本高昂。 卫星数据已被广泛用作估计全球范围内生物量的宝贵工具。 然而，密集多模态卫星时间序列数据与现代深度学习（DL）方法相结合的全部潜力尚未得到充分开发。 “BioMassters”数据挑战和基准数据集的目的是调查多模态卫星数据（Sentinel-1 SAR 和 Sentinel2 MSI）利用芬兰森林中心的开放森林和自然机载数据大规模估计森林生物量的潜力 LiDAR数据作为参考。 前三个基线模型的性能显示了深度学习生成准确且更高分辨率的生物量图的潜力
  
### Time Series as Images: Vision Transformer for Irregularly Sampled Time Series
- [[paper](https://arxiv.org/pdf/2303.12799.pdf)]
- [[code](https://github.com/Leezekun/ViTST)]
- 不规则采样的时间序列越来越普遍，特别是在医学领域。 尽管已经开发了各种专门方法来处理这些不规则性，但有效地对其复杂的动态和明显的稀疏性进行建模仍然是一个挑战。 本文引入了一种新颖的视角，将不规则采样的时间序列转换为线图图像，然后利用强大的预训练视觉变换器以与图像分类相同的方式进行时间序列分类。 这种方法不仅大大简化了专门的算法设计，而且还具有作为时间序列建模通用框架的潜力。 值得注意的是，尽管我们的方法很简单，但在几个流行的医疗保健和人类活动数据集上，我们的方法优于最先进的专用算法。 特别是在测试过程中省略部分变量的严格的离开传感器设置中，我们的方法对不同程度的缺失观察表现出很强的鲁棒性，即使在 一半的变量被屏蔽。

### Scale-teaching: Robust Multi-scale Training for Time Series Classification with Noisy Labels
 - [[paper](https://openreview.net/pdf?id=9D0fELXbrg)]
 - [[code](https://github.com/qianlima-lab/Scale-teaching)]
 - 深度神经网络 (DNN) 受到批评，因为它们很容易过度拟合噪声（不正确）的标签。 为了提高 DNN 的鲁棒性，现有的图像数据方法将训练损失较小的样本视为正确标记的数据（小损失准则）。 然而，在记录过程中，时间序列的判别模式很容易被外部噪声（即频率扰动）扭曲。 这导致一些不满足小损失准则的时间序列样本的训练损失。 因此，本文提出了一种称为Scale-teaching的深度学习范式来应对时间序列噪声标签。 具体来说，我们设计了一种从细到粗的跨尺度融合机制，通过利用不同尺度的时间序列同时训练多个 DNN 来学习判别模式。 同时，通过使用不同尺度的互补信息以交叉教学的方式训练每个网络，以选择小损失样本作为干净标签。 对于未选择的大损失样本，我们通过标签传播引入多尺度嵌入图学习，以使用选定的干净样本来纠正其标签。 对多个基准时间序列数据集的实验证明了所提出的量表教学范式在有效性和鲁棒性方面优于最先进的方法
